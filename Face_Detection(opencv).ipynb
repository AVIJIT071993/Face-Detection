{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Face Detection:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import opencv for face detection\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single Face:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Path of the haarcascade_frontalface_default.xml\n",
    "face_cascade=cv2.CascadeClassifier(\"C:\\\\Users\\\\avijit\\\\Desktop\\\\face_detection\\\\haarcascade_frontalface_default.xml\")\n",
    "\n",
    "#Path of the image on which you want to apply face detection\n",
    "img = cv2.imread(\"C:\\\\Users\\\\avijit\\\\Desktop\\\\face_detection\\\\Single.jpg\")\n",
    "\n",
    "#Converts image to grayscale for feature detection\n",
    "gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "#Detect the face in the image\n",
    "faces = face_cascade.detectMultiScale(gray_img, scaleFactor=1.05, minNeighbors=5)\n",
    "\n",
    "#Resize the image\n",
    "resized_image=cv2.resize(img, (int(img.shape[1]/2), int(img.shape[0]/2)))\n",
    "\n",
    "#Make rectangle box over the faces\n",
    "for x,y,w,h in faces:\n",
    "    resized_image=cv2.rectangle(img, (x,y), (x+w,y+h),(0,255,0),3)\n",
    "\n",
    "#Show the image as output\n",
    "cv2.imshow(\"Single Face\", resized_image)\n",
    "\n",
    "#wait until user presses the key\n",
    "cv2.waitKey(0)\n",
    "\n",
    "#Closes all windows\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiple Faces:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Path of the haarcascade_frontalface_default.xml\n",
    "face_cascade=cv2.CascadeClassifier(\"C:\\\\Users\\\\avijit\\\\Desktop\\\\face_detection\\\\haarcascade_frontalface_default.xml\")\n",
    "\n",
    "#Path of the image on which you want to apply face detection\n",
    "img = cv2.imread(\"C:\\\\Users\\\\avijit\\\\Desktop\\\\face_detection\\\\Multiple2.jpg\")\n",
    "\n",
    "#Converts image to grayscale for feature detection\n",
    "gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "#Detect the face in the image\n",
    "faces = face_cascade.detectMultiScale(gray_img, scaleFactor=1.05, minNeighbors=5)\n",
    "\n",
    "#Resize the image\n",
    "resized_image=cv2.resize(img, (int(img.shape[1]/2), int(img.shape[0]/2)))\n",
    "\n",
    "#Make rectangle box over the faces\n",
    "for x,y,w,h in faces:\n",
    "    resized_image=cv2.rectangle(img, (x,y), (x+w,y+h),(0,255,0),3)\n",
    "\n",
    "#Show the image as output\n",
    "cv2.imshow(\"Mutiple Faces\", resized_image)\n",
    "\n",
    "#wait until user presses the key\n",
    "cv2.waitKey(0)\n",
    "\n",
    "#Closes all windows\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Video Capture:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Path of the haarcascade_frontalface_default.xml\n",
    "face_Cascade=cv2.CascadeClassifier(\"C:\\\\Users\\\\avijit\\\\Desktop\\\\face_detection\\\\haarcascade_frontalface_default.xml\")\n",
    "\n",
    "#Input your camera port number, mine is 0\n",
    "camera_port=0\n",
    "video=cv2.VideoCapture(camera_port)\n",
    "\n",
    "while True:\n",
    "    # Capture frame-by-frame\n",
    "    check, frames = video.read()\n",
    "    gray = cv2.cvtColor(frames, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_Cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30), flags=cv2.CASCADE_SCALE_IMAGE)\n",
    "    \n",
    "    # Draw a rectangle around the faces\n",
    "    for (x, y, w, h) in faces:\n",
    "        cv2.rectangle(frames, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "    \n",
    "    # Display the resulting frame\n",
    "    cv2.imshow('Video Capture', frames)\n",
    "    \n",
    "    #wait until user presses the \"q\" key\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "video.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
